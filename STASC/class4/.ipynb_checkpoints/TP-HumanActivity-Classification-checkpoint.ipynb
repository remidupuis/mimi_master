{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activities - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce TP nous allons mettre en pratique plusieurs méthodes de classification supervisée sur des données d'enregistrement d'acceleromètres (de smart-phones).\n",
    "\n",
    "Les données sources sont disponibles sur [ici](http://bertrand.michel.perso.math.cnrs.fr/Enseignements/Data/UCI-HAR-Dataset.zip), voir aussi la description sur le site de [la plateforme de données UCI](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones).\n",
    "\n",
    "\"The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually.\n",
    "\n",
    "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details.\"\n",
    "\n",
    "L'objectif de ce TP est de retrouver l'activité à partir de toutes ces descripteurs (features). Notez que dans un contexte plus réaliste il vous faudrait créer par vosu même tous ces features qui décrivent les séries temporelles des accelerations enregistrées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données\n",
    "\n",
    "\n",
    "Les commandes suivantes permettent de récupérer les données.\n",
    "Pour simplifier on n'utilise pour le TP que les données du dossier \"train\".\n",
    "\n",
    "> Vérifiez que vous comprenez l'ensemble des commandes ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "votre_path= \"UCI-HAR-Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = votre_path + \"train/X_train.txt\"\n",
    "activity_features = pd.read_csv(data_path,delim_whitespace=True,\n",
    "                                header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des activités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = votre_path + \"train/y_train.txt\"\n",
    "activity  =    pd.read_csv(data_path,delim_whitespace=True,header=None)\n",
    "activity  =  activity.values[:,0] -  1 \n",
    "# la première activité sera 0 (plus pratique en python)\n",
    "activity_names = ['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable à prédire  est la variable d'activité. Il s'agit donc d'un problème de classification (à 6 classes).\n",
    "Pour cela on dispose des variables du tableau `activity_features`. \n",
    "> Combien de variables sont disponibles pour construire le prédicteur de l'activité ?  De combien d'observations dispose-t-on ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: 561 \n",
      " Observations: 7352\n"
     ]
    }
   ],
   "source": [
    "print(f'Variables: {activity_features.columns.size} \\n Observations: {activity_features.index.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour beaucoup de méthodes d'appprentissage statistique, il est conseiller de préalablement standardiser les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Effectuer une standardisation des features (activity_features) avec la fonction  [scale()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nor = preprocessing.scale(activity_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des sujets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = votre_path + \"train/subject_train.txt\"\n",
    "sujet =  pd.read_csv(data_path,delim_whitespace=True,header=None)\n",
    "sujet = sujet.values[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chaque sujet correspond plusieurs observations.\n",
    "> Indiquer le nombre d'observations de chaque sujet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sujet n° 1 à 347\n",
      "Sujet n° 3 à 341\n",
      "Sujet n° 5 à 302\n",
      "Sujet n° 6 à 325\n",
      "Sujet n° 7 à 308\n",
      "Sujet n° 8 à 281\n",
      "Sujet n° 11 à 316\n",
      "Sujet n° 14 à 323\n",
      "Sujet n° 15 à 328\n",
      "Sujet n° 16 à 366\n",
      "Sujet n° 17 à 368\n",
      "Sujet n° 19 à 360\n",
      "Sujet n° 21 à 408\n",
      "Sujet n° 22 à 321\n",
      "Sujet n° 23 à 372\n",
      "Sujet n° 25 à 409\n",
      "Sujet n° 26 à 392\n",
      "Sujet n° 27 à 376\n",
      "Sujet n° 28 à 382\n",
      "Sujet n° 29 à 344\n",
      "Sujet n° 30 à 383\n"
     ]
    }
   ],
   "source": [
    "s_id, s_counts = np.unique(sujet, return_counts = True)\n",
    "\n",
    "for i in range(s_id.size):\n",
    "    print(f'Sujet n° {s_id[i]} à {s_counts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème de classification à deux classes\n",
    "\n",
    "Dans toute la première partie du TP, on considère un problème de classification à deux classes. \n",
    "\n",
    "> Extraire les donnnés pour les activités  'WALKING_DOWNSTAIRS' (activity = 3)  et 'SITTING' (activity =4) uniquement. On appele `features34` et `activity34` les données correspondantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 561)\n"
     ]
    }
   ],
   "source": [
    "n,p = shape(features_nor)\n",
    "index_act34 = [i for i in range(n) if activity[i] in [3, 4]] \n",
    "activity34 = activity[index_act34]\n",
    "features34 = features_nor[index_act34]\n",
    "print(shape(features34))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présélection de features  pour réduire la dimension (screening)\n",
    "\n",
    "Pour diminuer les temps de calul on peut pré-sélectionner les 100 features les plus discriminants via un critère univarié. \n",
    "\n",
    "> Utiliser le critère  [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) basé sur la F-value (variance inter / variance intra).\n",
    "\n",
    "Attention, cette méthode ne garantit en rien que l'on choisisse ainsi le \"meilleur\" groupe de 100 variables pour le problème de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2660, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "Selec = SelectKBest(k = 100)\n",
    "features34 = Selec.fit_transform(X = features34, y = activity34)\n",
    "shape(features34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustement et prédiction pour des méthodes classiques de classification \n",
    "\n",
    "> Pour chacune des méthodes de classificiation listées ci-dessous, ajuster un predicteur de l'activité en utilisant comme données d'apprentissage la base (features34,activity34) :      \n",
    "- Classifieur naif bayesien avec la fonction `GaussianNB()`   \n",
    "- Classifieur des k plus proches voisins avec `neighbors.KNeighborsClassifier()` avec 5 plus proches voisins.  \n",
    "- Classifieur par régression logistique avec pénalisation ridge, en utilisant la fonction `linear_model.LogisticRegression() `. Indiquer la pénalité \"l2\" dans les arguments de la fonction et choisir le solveur \"saga\" (voir la doc de la fonction).\n",
    "\n",
    "\n",
    "Une présentation de chacune des ces fonctions est disponible sur cette [page](http://scikit-learn.org/stable/user_guide.html).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='saga')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X = features34, y = activity34)\n",
    "\n",
    "from sklearn import neighbors\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "nn.fit(X = features34, y = activity34)\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit =  linear_model.LogisticRegression(penalty = 'l2', solver = 'saga')\n",
    "logit.fit(X = features34, y = activity34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chacune de ces méthodes, on peut faire une prédiction grâce à la méthode `predict()`. par exemple pour le classifieur naif bayesien : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "feat_pred_gnb = gnb.predict(features34)\n",
    "print(feat_pred_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Faire de même une prédiction pour le classifieur des plus proches voisins et pour la régression logistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pred_nn = nn.predict(features34)\n",
    "feat_pred_logit = logit.predict(features34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ces prédictions sont-elles cohérentes entre elles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf Matrix between feat_pred_gnb and feat_pred_logit: \n",
      " [[0.75436328 0.24563672]\n",
      " [0.1015274  0.8984726 ]]\n",
      "Conf Matrix between feat_pred_gnb and feat_pred_nn: \n",
      " [[0.72721396 0.27278604]\n",
      " [0.09254268 0.90745732]]\n",
      "Conf Matrix between feat_pred_logit and feat_pred_nn: \n",
      " [[0.9125     0.0875    ]\n",
      " [0.04347826 0.95652174]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f\"Conf Matrix between feat_pred_gnb and feat_pred_logit: \\n {confusion_matrix(feat_pred_gnb, feat_pred_logit, normalize = 'true')}\")\n",
    "print(f\"Conf Matrix between feat_pred_gnb and feat_pred_nn: \\n {confusion_matrix(feat_pred_gnb, feat_pred_nn, normalize = 'true')}\")\n",
    "print(f\"Conf Matrix between feat_pred_logit and feat_pred_nn: \\n {confusion_matrix(feat_pred_logit, feat_pred_nn, normalize = 'true')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pour chaque prédicteur :\n",
    "> - Calculer le taux d'erreur \"à la main\" en comparant les observations et les prédictions.\n",
    "> - Calculer le taux de bon classement avec la méthode `score()` (disponible pour tout predicteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error a la main of nn: 0.039097744360902256\n",
      "Score of nn: 0.9609022556390977\n",
      "Error a la main of logit: 0.0406015037593985\n",
      "Score of logit: 0.9593984962406015\n",
      "Error a la main of gnb: 0.1943609022556391\n",
      "Score of gnb: 0.8056390977443609\n"
     ]
    }
   ],
   "source": [
    "dict = {'nn': feat_pred_nn, 'logit': feat_pred_logit, 'gnb': feat_pred_gnb}\n",
    "for prediction in dict.keys():\n",
    "    print(f'Error a la main of {prediction}: {mean((dict[prediction]-activity34)**2)}')\n",
    "    print(f'Score of {prediction}: {eval(prediction).score(X = features34, y = activity34)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidemment ce n'est pas pas la bonne façon d'estimer le risque de l'estimateur : estimer de l'erreur de généralisation en évaluant les erreurs sur l'échantillon qui a déjà servi à ajuster le prédicteur conduit la plupart du temps à une estimation trop optimiste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation de l'erreur par découpage train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant évaluer l'erreur de généralisation en conservant une partie de l'échantillon pour évaluer les erreurs du prédicteur ajusté. Pour cela on découpe aléatoirement l'échantillon initial en deux parties :  \n",
    "\n",
    "- l'ensemble d'apprentissage : utilisé pour ajuster les prédicteurs ;\n",
    "- l'ensemble de test : utilisé pour évaluer les performances des prédicteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Utiliser la fonction <code>train_test_split</code> du module [<code>model_selection</code>](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) pour construire un échantillon d'apprentissage de taille 60% (et donc 40% réservées aux données de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.6\n",
      "(1596, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "features_train, features_test, activity_train, activity_test = model_selection.train_test_split(features34, activity34, test_size = 0.6)\n",
    "print(len(activity_train)/ float(len(activity34)))\n",
    "print(len(activity_test)/ float(len(activity34)))\n",
    "print(shape(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluer le risque d'un classifieur par plus proches voisins (knn) avec 5 voisins sur ce découpage des données : ajuster sur les données d'apprentissage et évaluer les erreurs sur le test.  \n",
    ">\n",
    "> Vérifier que l'estimation de l'erreur ainsi obtenue est plus élevée que l'estimation obtenue précédemment, en ajustant et évaluant l'erreur sur le même échantillon (échantillon complet, sans découpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X = features_train, y = activity_train)\n",
    "knn.score(X = features_test, y = activity_test)\n",
    "\n",
    "# Indeed, smaller than 96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reproduire la procédure 100 fois et dresser le boxplot de l'estimation de l'erreur sur ces 100 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train_test = [] # pour stockage des scores\n",
    "for simu in range(100) :\n",
    "    features_train, features_test, activity_train, activity_test = model_selection.train_test_split(features34, activity34, test_size = 0.6)\n",
    "    nn_train_test = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "    nn_train_test.fit(X = features_train, y = activity_train)\n",
    "    score_train_test.append(nn_train_test.score(X = features_test, y = activity_test))\n",
    "B = plt.boxplot(score_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tracer la courbe d'erreur du classifieur par plus proches voisins en fonction du nombre de voisins utilisés (de 1 à 15), en utilisant cette méthode de découpage train / test répétée 20 fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_score_train_test = []\n",
    "for k in range(1,16):\n",
    "    score_train_test = [] # pour stockage des scores\n",
    "    for simu in range(20) :\n",
    "        features_train, features_test, activity_train, activity_test = model_selection.train_test_split(features34, activity34, test_size = 0.6)\n",
    "        nn_train_test = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "        nn_train_test.fit(X = features_train, y = activity_train)\n",
    "        score_train_test.append(nn_train_test.score(X = features_test, y = activity_test))\n",
    "    all_score_train_test.append(score_train_test)\n",
    "B = plt.boxplot(all_score_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité, si l'on désire une estimation du modèle sélectionné ainsi, il faut découper l'échantillon disponible non pas en deux mais en trois parties :\n",
    "- l'ensemble d'apprentissage : utilisé pour construire des modèles ;\n",
    "- l'ensemble de validation : utilisé pour choisir un modèle ;\n",
    "- l'ensemble de test : utilisé pour évaluer les performances du modèle\n",
    "  finalement choisi.\n",
    "  \n",
    "Ceci est notamment important lorsque l'on souhaite comparer deux méthodes qui ont toutes les deux fait intervenir un réglage de paramètres (ici le nombre de voisins).\n",
    "\n",
    "> **Question bonus** (finir le tp avant de répondre à cette question) : Mettre en oeuvre cette méthode pour estimer l'erreur de généralisation du prédicteur knn pour lequel le nombre de voisins est choisi via l'échantillon de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation du risque par validation croisée \n",
    "\n",
    "On présente ci-dessous la méthode du de validation croisée de type **k-fold**.\n",
    "\n",
    "L'idée principale est de faire jouer à chaque observation à la fois le rôle de donnée d'apprentissage et celui de donnée de validation. \n",
    "\n",
    "Le principe consiste à partitionner aléatoirement les données $D=(\\mathbf{x}_i,y_i)_{1\\leq i\\leq N} $ \n",
    "en $K$ blocs disjoints de tailles comparables :\n",
    "$D^1,\\ldots,D^K$. On prend généralement $K=5$ ou $10$. La méthode du **leave-one-out (Loo)** correspond au choix $K=N$. \n",
    "\n",
    "On estime alors la qualité d'un predicteur $\\hat f$ de la\n",
    "façon suivante :\n",
    "- pour tout $k \\in \\{1,\\dots, K\\}$, on construit un predicteur $\\hat f^k$ (du même type que $\\hat f$) sur l'ensemble d'apprentissage $D^{-k} := D\\setminus D^k$ ;\n",
    "- on estime le risque du prédicteur $\\hat f$ par   \n",
    "$$\n",
    "\\frac{1}{N}\\sum_{k=1}^K\\sum_{\\mathbf{x}_i\\in D^k} \\ell(\\hat f^k(\\mathbf{x}_i),y_i),\n",
    "$$\n",
    "où $\\ell$ est la perte utilisée.\n",
    "\n",
    "On construit donc autant de prédicteurs qu'il y a de blocs dans\n",
    "l'ensemble d'apprentissage. Chaque prédicteur est évalué sur les éléments du\n",
    "bloc qui n'a pas été utilisé pour l'apprentissage (et qui joue donc le rôle d'\n",
    "ensemble de validation). \n",
    "\n",
    "Lorsque l'on souhaite régler un paramètre en utilisant la validation croisée, par exemple le nombre de voisins $k$ pour knn, on procède comme suit :\n",
    "- on évalue les performances des prédicteurs par validation croisée comme expliqué ci-dessus ;\n",
    "- on détermine la valeur optimale du paramètre ;\n",
    "- on construit finalement un predicteur pour le paramètre sélectionné, en utilisant comme base d'apprentissage toutes les données.\n",
    "\n",
    "\n",
    "**Comparaison entre LOO et methodes k folds, quelques repères :** \n",
    "- LOO a un coût computationnel plus élevé que les méthodes k-fold pour k petit (pour k = 5 ou 10 par exemple)\n",
    "- L'estimation de l'erreur fournie par LOO a généralement une variance plus élevée que celles obtenues par un k-fold pour k petit.\n",
    "- En revanche, si l'erreur de classification décroit très rapidement avec $n$, les méthodes k-fold avec k petit peuvent surestimer significativement l'erreur de généralisation.\n",
    "- En général, il est souvent recommandé d'utiliser les méthodes k-fold avec k = 5 ou 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble des méthodes de validation croisée disponibles sous `sklearn` sont disponibles dans le module [<code>model_selection</code>](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection). Voir aussi le [guide](https://scikit-learn.org/stable/modules/cross_validation.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation de l'erreur par 10-fold :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90601504 0.83458647 0.85338346 0.81578947 0.87593985 0.80451128\n",
      " 0.91353383 0.95864662 0.84586466 0.88345865]\n",
      "0.8691729323308272\n"
     ]
    }
   ],
   "source": [
    "nn_val_croisee = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "scores = model_selection.cross_val_score(nn_val_croisee, features34, y = activity34, cv=10) # Estimator, X, y, cross-validation splitting strategy\n",
    "print(scores)\n",
    "print(mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention cependant, avec cette méthode, la fonction `cross_val_score` ne permute pas préalablement les données avant de définir les blocs. Voir cette [note](https://scikit-learn.org/stable/modules/cross_validation.html#a-note-on-shuffling) dans la doc de sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Modifier la procédure pour que les données soient bien initiallement permutées. On utilise pour cela un \"iterateur\" de validation croisée, que l'on définit ici avec la fonction `KFold`, et que l'on fournit en argument de la fonction `cross_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92481203, 0.91917293, 0.91729323, 0.90789474, 0.93233083])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_kfold = model_selection.KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "nn_val_croisee = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "# cv: int, cross-validation generator or an iterable, default=None\n",
    "scores = model_selection.cross_val_score(\n",
    "    estimator = nn_val_croisee,\n",
    "    X = features34,\n",
    "    y = activity34,\n",
    "    cv = my_kfold,\n",
    "    n_jobs = -1) # permet de répartir les calculs sur plusieurs coeurs\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation de l'erreur par Loo\n",
    "\n",
    "\n",
    "> Utiliser la fonction <code>LeaveOneOut</code> de `model_selection` pour évaluer l'erreur du classifieur de plus proches voisin (pour 10 voisins).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_val_croisee = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "scores = model_selection.cross_val_score(nn_val_croisee, \n",
    "                                         features34, \n",
    "                                         y = activity34, \n",
    "                                         cv=model_selection.LeaveOneOut()) # Estimator, X, y, cross-validation splitting strategy\n",
    "print(scores)\n",
    "print(mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La question de la permutation aléatoire initiale des données se pose-t-elle ici aussi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection du nombre de plus proches voisins par validation croisée 10 fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Selectionner un nombre de voisins pour le classifieur de plus proches voisins par validation croisée 10 fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kfold = model_selection.KFold(n_splits = 10, shuffle = True, random_state=0)\n",
    "\n",
    "k_scores = []\n",
    "for k in range(1,16):\n",
    "    nn_val_croisee = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    scores = model_selection.cross_val_score(estimator = nn_val_croisee,\n",
    "                                             X = features34,\n",
    "                                             y = activity34,\n",
    "                                             cv = my_kfold,\n",
    "                                             n_jobs = -1) \n",
    "    k_scores.append(scores)\n",
    "boxplots = plt.boxplot(all_score_train_test)\n",
    "\n",
    "# Par l'analyse du graph suivant, a priori 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La fonction GridSearchCV\n",
    "\n",
    "En apprentissage statistique, on a très souvent recours à la validation croisée pour régler des paramètres de la méthode utilisée. La fonction [gridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) permet d'effectuer cette tâche de façon simple, en répartissant éventuellement les calculs sur plusieurs coeurs (voir plus bas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "# la grille de parametres a regler sont definis dans un dictionnaire (dict)\n",
    "tuned_parameters = {'n_neighbors': range(2,20)}\n",
    "start = time()\n",
    "\n",
    "my_kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "nnGrid = GridSearchCV(neighbors.KNeighborsClassifier(),\n",
    "                      tuned_parameters,\n",
    "                      #cv=5)  # >>>>> Why not using kfold as I did here? Error?\n",
    "                      cv = my_kfold)           \n",
    "nnGrid.fit(features34, activity34)\n",
    "print(str(time() - start)+ \" sec\")\n",
    "\n",
    "# le meilleur modele \n",
    "print(nnGrid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Si votre machine le permet, utiliser maintenant plusieurs coeurs (argument \"n_jobs= \") et comparer les temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'n_neighbors': range(2,20)}\n",
    "start = time()\n",
    "\n",
    "my_kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "nnGrid = GridSearchCV(neighbors.KNeighborsClassifier(),\n",
    "                      tuned_parameters,\n",
    "                      n_jobs = -1,\n",
    "                      #cv=5)  # >>>>> Why not using kfold as I did here? Error?\n",
    "                      cv = my_kfold)           \n",
    "nnGrid.fit(features34, activity34)\n",
    "print(str(time() - start)+ \" sec\")\n",
    "\n",
    "# le meilleur modele \n",
    "print(nnGrid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification multiclasses \n",
    "\n",
    "Pour réduire les temps de calcul (il s'agit d'un TP...) nous appliquons la même stratégie de présélection de features que nous avons utilisé pour la classification binaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présélection de features\n",
    "\n",
    "Pour réduire les temps de calcul (il s'agit d'un TP...) nous appliquons la même stratégie de présélection de features que pour le cas à deux classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selec = SelectKBest(f_classif, k=100)\n",
    "features_all_activities = Selec.fit_transform(activity_features, activity)\n",
    "shape(features_all_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifieur naif bayesien multiclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "scores  = model_selection.cross_val_score(gnb, features_all_activities, activity, cv=my_kfold)\n",
    "print(scores)\n",
    "print(mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifieur des k plus proches voisins multiclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "scores  = model_selection.cross_val_score(nn, features_all_activities, activity, cv=my_kfold)\n",
    "print(scores)\n",
    "print(mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Effectuer un découpage apprentissage / test des données (avec toutes les classes).\n",
    "> Utiliser la fonction `GridSearchCV` sur l'échantillon d'apprentissage pour choisir le nombre de voisins pour l'estimateur knn. Dresser et afficher la matrice de confusion sur les données de test, voir [ici](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) et [ici](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage apprentissage / test des données (avec toutes les classes).\n",
    "features_train, features_test, activity_train, activity_test = model_selection.train_test_split(\n",
    "    features_nor, \n",
    "    activity, \n",
    "    test_size = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisant la fonction GridSearchCV\n",
    "tuned_parameters = {'n_neighbors': range(2,20)}\n",
    "start = time()\n",
    "\n",
    "my_kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "nnGrid = GridSearchCV(neighbors.KNeighborsClassifier(),\n",
    "                      tuned_parameters,\n",
    "                      n_jobs = -1,\n",
    "                      cv = my_kfold)           \n",
    "nnGrid.fit(features_train, activity_train)\n",
    "print(str(time() - start)+ \" sec\")\n",
    "\n",
    "# le meilleur modele \n",
    "print(nnGrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nn_model = neighbors.KNeighborsClassifier(n_neighbors = nnGrid.best_params_['n_neighbors'])\n",
    "\n",
    "reg = final_nn_model.fit(X = features_train, y = activity_train)\n",
    "\n",
    "y_pred = reg.predict(X = features_test)\n",
    "\n",
    "print(confusion_matrix(y_pred = y_pred, y_true = activity_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
